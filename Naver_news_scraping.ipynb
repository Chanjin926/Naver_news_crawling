{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b411c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78ec9a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame에 들어갈 list 생성\n",
    "dates = []\n",
    "category = []\n",
    "press = []\n",
    "titles = []\n",
    "documents = []\n",
    "link = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72430ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작, 종료 날짜 현재 기준으로 설정, 페이지값 초기화(이건 나중에 옮기기)\n",
    "curr_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "end_date = (datetime.now() - relativedelta(days=3)).strftime(\"%Y%m%d\")\n",
    "page = 1\n",
    "count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77a69b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_source(search_date, search_page):\n",
    "    url = \"https://news.naver.com/main/list.naver?mode=LS2D&mid=shm&sid2=230&sid1=105&date=\" + search_date + \"&page=\" + str(search_page)\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'}\n",
    "    web = requests.get(url, headers=headers).content\n",
    "    source = BeautifulSoup(web, 'html.parser')\n",
    "    \n",
    "    return source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1171c24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_news(url, dates, category, press, titles, documents, link):\n",
    "    try:\n",
    "        content = requests.get(url).content\n",
    "        source = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "        # 기사날짜\n",
    "        date = source.find('span', {'class': 'media_end_head_info_datestamp_time _ARTICLE_DATE_TIME'}).get_text()\n",
    "\n",
    "        # 언론사\n",
    "        company = source.find('em', {'class' : 'media_end_linked_more_point'}).get_text()\n",
    "        \n",
    "        # 기사제목\n",
    "        title = source.find('h2').get_text()\n",
    "\n",
    "        # 기사본문\n",
    "        article = source.find('article', {'id': 'dic_area'}).get_text()\n",
    "        news_content = article.replace(\"\\n\", \"\")\n",
    "        news_content = news_content.replace(\"// flash 오류를 우회하기 위한 함수 추가function _flash_removeCallback() {}\", \"\")\n",
    "        news_content = news_content.replace(\"동영상 뉴스       \", \"\")\n",
    "        news_content = news_content.replace(\"동영상 뉴스\", \"\")\n",
    "        news_content = news_content.strip()\n",
    "\n",
    "        dates.append(date)\n",
    "        category.append(\"IT 일반\")\n",
    "        press.append(company)\n",
    "        titles.append(title)\n",
    "        documents.append(news_content)\n",
    "        link.append(url)\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cba5b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:53<00:00, 17.34s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [08:41<00:00, 17.97s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [09:37<00:00, 22.20s/it]\n"
     ]
    }
   ],
   "source": [
    "# Main Code\n",
    "while curr_date != end_date:\n",
    "    # page 값 초기화\n",
    "    page = 1\n",
    "    \n",
    "    # max page 구하기\n",
    "    source = call_source(curr_date, 100)\n",
    "    max_page = int(source.find_all('strong')[2].get_text())\n",
    "    max_page += 1 # range 함수 고려\n",
    "    \n",
    "    for pg in tqdm(range(1, max_page)):\n",
    "        # 현재 페이지 정보 불러오기\n",
    "        source = call_source(curr_date, page)\n",
    "        page_list = source.find_all('a', {'class' : 'nclicks(fls.page)'})\n",
    "\n",
    "        # 각 기사별 링크 추출\n",
    "        article_list = []\n",
    "        article_set = source.find_all('dt')\n",
    "\n",
    "        for info in article_set:\n",
    "            url = info.find('a')['href']\n",
    "            article_list.append(url)\n",
    "\n",
    "        article_list = list(dict.fromkeys(article_list))\n",
    "\n",
    "        # 각 기사별 스크랩 진행\n",
    "        for url in article_list:\n",
    "            scrap_news(url, dates, category, press, titles, documents, link)\n",
    "\n",
    "        # 다음 페이지\n",
    "        page += 1\n",
    "        \n",
    "    # 날짜, page 초기화\n",
    "    curr_date = (datetime.now() - relativedelta(days=count)).strftime(\"%Y%m%d\")\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dca7b9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Category</th>\n",
       "      <th>Press</th>\n",
       "      <th>Title</th>\n",
       "      <th>Document</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023.10.06. 오전 11:23</td>\n",
       "      <td>IT 일반</td>\n",
       "      <td>연합뉴스</td>\n",
       "      <td>[게시판] 코스콤, 롯데카드 클라우드 컨택센터 구축 완료</td>\n",
       "      <td>[코스콤 제공. 재판매 및 DB 금지]    ▲ 코스콤은 네이버클라우드와 함께 최근...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/001/001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023.10.06. 오전 11:23</td>\n",
       "      <td>IT 일반</td>\n",
       "      <td>이데일리</td>\n",
       "      <td>동아ST-GC녹십자, 면역질환 신약개발에 머리 맞댄다</td>\n",
       "      <td>[이데일리 나은경 기자] 동아에스티(170900)는 GC녹십자(006280)와 면역...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/018/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023.10.06. 오전 11:23</td>\n",
       "      <td>IT 일반</td>\n",
       "      <td>지디넷코리아</td>\n",
       "      <td>\"4년간 연구했다\"…하림 '더미식 육즙만두' 맛보니</td>\n",
       "      <td>\"얇고 쫄깃한 만두피·촉촉한 육즙 합격\"...냉동만두 시장 10% 점유 목표\"4년간...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/092/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023.10.06. 오전 11:22</td>\n",
       "      <td>IT 일반</td>\n",
       "      <td>헤럴드경제</td>\n",
       "      <td>DGIST 학생 창업기업, 창업아이디어 경진대회 석권</td>\n",
       "      <td>이정우(오른쪽) 퀘스터 대표와 김규민 Friending 대표.[DGIST 제공][헤...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/016/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023.10.06. 오전 11:21</td>\n",
       "      <td>IT 일반</td>\n",
       "      <td>헤럴드경제</td>\n",
       "      <td>사우디 통신정보기술부 장관, 네이버 1784 방문...미래기술 논의</td>\n",
       "      <td>AI·디지털트윈 기술협력 가능성5일 네이버 1784에 방문한 사우디아라비아 통신정보...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/016/000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Date Category   Press  \\\n",
       "0  2023.10.06. 오전 11:23    IT 일반    연합뉴스   \n",
       "1  2023.10.06. 오전 11:23    IT 일반    이데일리   \n",
       "2  2023.10.06. 오전 11:23    IT 일반  지디넷코리아   \n",
       "3  2023.10.06. 오전 11:22    IT 일반   헤럴드경제   \n",
       "4  2023.10.06. 오전 11:21    IT 일반   헤럴드경제   \n",
       "\n",
       "                                   Title  \\\n",
       "0        [게시판] 코스콤, 롯데카드 클라우드 컨택센터 구축 완료   \n",
       "1          동아ST-GC녹십자, 면역질환 신약개발에 머리 맞댄다   \n",
       "2           \"4년간 연구했다\"…하림 '더미식 육즙만두' 맛보니   \n",
       "3          DGIST 학생 창업기업, 창업아이디어 경진대회 석권   \n",
       "4  사우디 통신정보기술부 장관, 네이버 1784 방문...미래기술 논의   \n",
       "\n",
       "                                            Document  \\\n",
       "0  [코스콤 제공. 재판매 및 DB 금지]    ▲ 코스콤은 네이버클라우드와 함께 최근...   \n",
       "1  [이데일리 나은경 기자] 동아에스티(170900)는 GC녹십자(006280)와 면역...   \n",
       "2  \"얇고 쫄깃한 만두피·촉촉한 육즙 합격\"...냉동만두 시장 10% 점유 목표\"4년간...   \n",
       "3  이정우(오른쪽) 퀘스터 대표와 김규민 Friending 대표.[DGIST 제공][헤...   \n",
       "4  AI·디지털트윈 기술협력 가능성5일 네이버 1784에 방문한 사우디아라비아 통신정보...   \n",
       "\n",
       "                                                Link  \n",
       "0  https://n.news.naver.com/mnews/article/001/001...  \n",
       "1  https://n.news.naver.com/mnews/article/018/000...  \n",
       "2  https://n.news.naver.com/mnews/article/092/000...  \n",
       "3  https://n.news.naver.com/mnews/article/016/000...  \n",
       "4  https://n.news.naver.com/mnews/article/016/000...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df = pd.DataFrame({'Date':dates,\n",
    "                          'Category':category,\n",
    "                          'Press':press,\n",
    "                          'Title':titles,\n",
    "                          'Document':documents,\n",
    "                          'Link':link})\n",
    "\n",
    "article_df.to_excel('result_{}.xlsx'.format(datetime.now().strftime('%y%m%d_%H%M')), index=False)\n",
    "article_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdec0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
